# Hey, I'm Sudhanshu! 👋  

I’m a **Data Science Master’s student at the University of Michigan, Ann Arbor**, working on **LLMs, information retrieval, and machine learning systems**. My work revolves around **optimizing LLM architectures, improving retrieval-augmented generation (RAG) pipelines, and building scalable models for real-world applications**.  

I’m passionate about **designing better search and ranking systems, improving how LLMs retrieve and generate information, and making deep learning models more efficient**. Whether it's **fine-tuning LLMs, optimizing retrieval-based architectures, or applying machine learning to large-scale datasets**, I enjoy working on challenges that push the limits of what AI can do.  

---

## 🔍 A Few Things I’m Really Into Right Now  
- **Optimizing LLMs for efficiency** – Fine-tuning, parameter-efficient learning, and retrieval-based architectures to **make LLMs faster and more adaptable**.  
- **Search & Retrieval for LLMs** – Improving **ranking models, hybrid search techniques, and knowledge-grounded generation** to ensure **LLMs retrieve the right information before generating text**.  
- **Multi-modal Learning** – Exploring how **LLMs can process text, images, and structured data together** to build more intelligent and context-aware models.  

---

## 💡 Some Cool Projects I’ve Worked On  
- **LLMs & Machine Learning for Healthcare & Genomics** – At **University of Michigan**, I worked on analyzing **single-cell RNA sequencing data** to understand **how cancerous cells behave differently from healthy ones**. It was a deep dive into **biomedical data science, clustering techniques, and handling massive biological datasets**, using ML techniques to extract meaningful insights.  
- **Optimizing LLM Architectures** – Developed a **hybrid attention model** that balances inference speed and memory efficiency. It involved **fine-tuning LLMs, exploring low-rank adaptation, and optimizing deep learning architectures** for scalability.  
- **Retrieval-Augmented Generation (RAG) for Better Search** – Built a **medical information retrieval system** that integrates **learning-to-rank models with LLM-powered responses**. This project taught me **how search and ranking models impact generative AI outputs** and how **retrieval-based architectures can make LLMs more reliable**.  
- **Predictive Analytics for Market & Behavioral Trends** – I’ve worked on **financial forecasting and sentiment analysis**, including an **F1 Twitter sentiment analysis** that explored **how fan emotions influence race narratives**. It was a fun way to combine **machine learning, NLP, and behavioral modeling**.  

---

## 🌱 What I’m Currently Learning & Exploring  
- **Optimizing LLMs for efficiency** – Fine-tuning, quantization, low-rank adaptation—exploring ways to **make large models faster and more scalable**.  
- **Multi-modal Retrieval & Learning** – How can LLMs **combine text, images, and structured data to improve search, recommendations, and content generation**?  
- **Improving Search & Ranking for LLMs** – LLMs generate great responses, but **only if they retrieve the right context**. I’ve been working on **hybrid search, vector embeddings, and knowledge-grounded generation** to improve **how LLMs retrieve and rank information**.  

---

## 🛠️ The Tools I Use (and Occasionally Break)  
I work across **machine learning, retrieval systems, and cloud infrastructure**, using a mix of:  

- **Programming & ML** – Python, C/C++, Java, R, PyTorch, TensorFlow, scikit-learn  
- **NLP & Retrieval** – Hugging Face, spaCy, Learning-to-Rank, RAG Pipelines  
- **Big Data & Cloud** – AWS, GCP, Azure, Spark, Kafka, Airflow  
- **MLOps & Deployment** – Docker, FastAPI, Flask, Kubernetes, MLflow  
- **Data Analytics & Viz** – SQL, Tableau, Matplotlib, Seaborn, Plotly  

I’m always eager to learn and explore new technologies that enhance **LLMs, retrieval, and scalable ML systems**. 🚀  

---

## 🎖️ A Few Things I’m Proud Of  
🏆 **Mitacs Globalink Graduate Fellowship** – Awarded for research in **LLMs and machine learning**.  
📜 **AWS Certified Cloud Practitioner** – Because **ML models need scalable cloud deployments**.  
📜 **BCG Data Science & Advanced Analytics Program** – Hands-on experience with **business-driven ML solutions**.  

---

## 📫 Let’s Connect!  
I’m always up for **discussing LLMs, retrieval models, and anything related to search and ranking**. If you want to **collaborate, share ideas, or geek out about deep learning**, feel free to reach out!  

📩 **Email**: sudhagar@umich.edu  
🔗 [**LinkedIn**](https://www.linkedin.com/in/sudhanshu-agarwal/)  
💻 [**GitHub**](https://github.com/SudhanshuAgarwal786)  

---

## 🔥 TL;DR?  
I **build, optimize, and deploy LLMs**, work on **retrieval-based search models**, and explore **ways to make machine learning more efficient and scalable**. I love tackling **complex problems in deep learning, NLP, and information retrieval**—and I’m always looking to learn more.  
